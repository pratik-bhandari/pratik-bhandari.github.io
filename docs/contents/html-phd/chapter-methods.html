<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>3 General methods | Interaction of top-down and bottom-up processes in spoken language comprehension</title>
<meta name="author" content="Pratik Bhandari">
<meta name="generator" content="bookdown 0.31 with bs4_book()">
<meta property="og:title" content="3 General methods | Interaction of top-down and bottom-up processes in spoken language comprehension">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="3 General methods | Interaction of top-down and bottom-up processes in spoken language comprehension">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="templates/bs4_style.css">
<link rel="stylesheet" href="templates/corrections.css">
<meta name="description" content="This chapter provides an overview of the experimental materials used in the experiments described in Chapters 5, 6, and 7. Sentences used as experimental material were common in all the...">
<meta property="og:description" content="This chapter provides an overview of the experimental materials used in the experiments described in Chapters 5, 6, and 7. Sentences used as experimental material were common in all the...">
<meta name="twitter:description" content="This chapter provides an overview of the experimental materials used in the experiments described in Chapters 5, 6, and 7. Sentences used as experimental material were common in all the...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title=""><p>Interaction of top-down and bottom-up processes in spoken language comprehension</p></a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="chapter-introduction.html"><span class="header-section-number">1</span> Introduction</a></li>
<li><a class="" href="chapter-background.html"><span class="header-section-number">2</span> Background</a></li>
<li><a class="active" href="chapter-methods.html"><span class="header-section-number">3</span> General methods</a></li>
<li><a class="" href="chapter-stats.html"><span class="header-section-number">4</span> General statistical approach</a></li>
<li><a class="" href="chapter-attention-prediction.html"><span class="header-section-number">5</span> Predictability effects of degraded speech are reduced as a function of attention</a></li>
<li><a class="" href="chapter-graded-prediction.html"><span class="header-section-number">6</span> Semantic predictability facilitates comprehension of degraded speech in a graded manner</a></li>
<li><a class="" href="chapter-speech-rate.html"><span class="header-section-number">7</span> Comprehension of degraded speech is modulated by the rate of speech</a></li>
<li><a class="" href="chapter-conclusion.html"><span class="header-section-number">8</span> Discussion and conclusion</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="appendix-A.html"><span class="header-section-number">A</span> Experimental items</a></li>
<li><a class="" href="appendix-B.html"><span class="header-section-number">B</span> Forward prediction vs Backward guessing in Chapter 6</a></li>
<li><a class="" href="appendix-C.html"><span class="header-section-number">C</span> Forward prediction vs Backward guessing in Chapter 7</a></li>
<li><a class="" href="appendix-D.html"><span class="header-section-number">D</span> Data and code</a></li>
<li><a class="" href="appendix-E.html"><span class="header-section-number">E</span> Ethics and funding</a></li>
<li><a class="" href="bibliography.html">Bibliography</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/pratik-bhandari">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="chapter-methods" class="section level1" number="3">
<h1>
<span class="header-section-number">3</span> General methods<a class="anchor" aria-label="anchor" href="#chapter-methods"><i class="fas fa-link"></i></a>
</h1>
<p>This chapter provides an overview of the experimental materials used in the experiments described in Chapters 5, 6, and 7.
Sentences used as experimental material were common in all the experiments,
and the signal processing method was also common.
Here, we also present an overview of online data collection.</p>
<div id="experimental-materials" class="section level2" number="3.1">
<h2>
<span class="header-section-number">3.1</span> Experimental materials<a class="anchor" aria-label="anchor" href="#experimental-materials"><i class="fas fa-link"></i></a>
</h2>
<p>As a part of a study in the research project A4 of SFB1102, sentences of different levels of predictability were created.
Digital recordings of the sentences were degraded by noise-vocoding and used in all experiments reported in this thesis.
The speech was also distorted by its compression and expansion.
Below we briefly describe how the sentences of different levels of predictability were obtained
and what methodology was used to create distorted versions of the speech.</p>
<div id="stimulus-sentences" class="section level3" number="3.1.1">
<h3>
<span class="header-section-number">3.1.1</span> Stimulus sentences<a class="anchor" aria-label="anchor" href="#stimulus-sentences"><i class="fas fa-link"></i></a>
</h3>
<p>With an aim to create sentences of three levels of predictability (low, medium, and high), a triplet of 120 sentences — a total of 360 sentences — were created from 120 nouns.
Out of 120 nouns, 6 were repeated.
All sentences were in present tense consisting of pronoun, verb, determiner, and object.
These sentences were in Subject-Verb-Object form (e.g., <em>Er fängt den Ball</em>. EN: He catches the ball.).
Some of these sentences were taken from <span class="citation">Obleser &amp; Kotz (<a href="bibliography.html#ref-Obleser2010" role="doc-biblioref">2010</a>)</span>.
For each sentence, cloze probability ratings were collected from a group of young adults (n = 60; age range = 18–30 years).
Mean cloze probabilities of low, medium and high probability sentences are shown in Table <a href="chapter-methods.html#tab:cloze-table">3.1</a> and
the distribution of cloze probability across low, medium, and high predictability sentences is shown in Figure <a href="chapter-methods.html#fig:cloze-distribution">3.1</a>.
The cloze probabilities of the target words in each sentence are shown in Appendix <a href="appendix-A.html#appendix-A">A</a>.
<!--
```{=tex}
\begin{table}[ht]
\begin{center}
\caption{Cloze probabilities of low, medium and high predictability sentences} 
\vskip 0.12in
\begin{tabular}{c c c}
\label{cloze-table} 
\toprule
 & \multicolumn{2}{c}{Cloze probability} \\
\cmidrule(l){2-3}
Predictability & Mean $\pm$ SD & Range \\
\midrule
Low & 0.022 $\pm$ 0.027 & 0.00 – 0.09 \\
Medium & 0.274 $\pm$ 0.134 & 0.1 – 0.55 \\
High & 0.752 $\pm$ 0.123 & 0.56 – 1.00 \\
\bottomrule
\end{tabular}
\end{center}
\end{table}
```
--></p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:cloze-table">Table 3.1: </span> Cloze probabilities of low, medium and high predictability sentences</caption>
<thead><tr class="header">
<th align="center"></th>
<th align="center">Cloze probability</th>
<th align="center"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center"><strong>Predictability</strong></td>
<td align="center">Mean <span class="math inline">\(\pm\)</span> SD</td>
<td align="center">Range</td>
</tr>
<tr class="even">
<td align="center">Low</td>
<td align="center">0.022 <span class="math inline">\(\pm\)</span> 0.027</td>
<td align="center">0.00 – 0.09</td>
</tr>
<tr class="odd">
<td align="center">Medium</td>
<td align="center">0.274 <span class="math inline">\(\pm\)</span> 0.134</td>
<td align="center">0.1 – 0.55</td>
</tr>
<tr class="even">
<td align="center">High</td>
<td align="center">0.752 <span class="math inline">\(\pm\)</span> 0.123</td>
<td align="center">0.56 – 1.00</td>
</tr>
</tbody>
</table></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:cloze-distribution"></span>
<img src="figures/materials/cloze-distribution.jpg" alt="Distribution of cloze probability ratings of target words in low, medium and high predictability sentences" width="90%"><p class="caption">
Figure 3.1: Distribution of cloze probability ratings of target words in low, medium and high predictability sentences
</p>
</div>
</div>
<div id="speech-processing" class="section level3" number="3.1.2">
<h3>
<span class="header-section-number">3.1.2</span> Speech processing<a class="anchor" aria-label="anchor" href="#speech-processing"><i class="fas fa-link"></i></a>
</h3>
<p>All 360 sentences were spoken by a female native speaker of German at a normal rate.
The recordings were digitized at 44.1kHz with 32-bit linear encoding.
Spoken sentences used in Chapters 5, 6, and 7 were degraded by noise-vocoding.
In addition to degradation by noise-vocoding, the sentences were distorted by compression and expansion of speech signal in Chapter 7.</p>
<div id="noise-vocoding" class="section level4" number="3.1.2.1">
<h4>
<span class="header-section-number">3.1.2.1</span> Noise-vocoding<a class="anchor" aria-label="anchor" href="#noise-vocoding"><i class="fas fa-link"></i></a>
</h4>
<p>Noise-vocoding is used to parametrically vary and control the speech quality in a graded manner.
It distorts a speech signal by dividing it into specific frequency bands corresponding to the number of vocoder channels.
The frequency bands are analogous to the electrodes of a cochlear implant <span class="citation">(<a href="bibliography.html#ref-Loizou1999" role="doc-biblioref">Loizou et al., 1999</a>; <a href="bibliography.html#ref-Shannon1995" role="doc-biblioref">R. V. Shannon et al., 1995</a>; <a href="bibliography.html#ref-Shannon2004" role="doc-biblioref">R. V. Shannon et al., 2004</a>)</span>.
The amplitude envelope, i.e., the fluctuations of amplitude within each frequency band, is extracted, and the spectral information within it is replaced by noise.
This noise-filtering makes the vocoded speech difficult to understand, although its temporal characteristics and periodicity of perceptual cues are preserved <span class="citation">(<a href="bibliography.html#ref-Rosen1999" role="doc-biblioref">Rosen et al., 1999</a>)</span>.</p>
<p>The spectral degradation conditions of 1, 4, 6, and 8 channels were achieved for each of the 360 recorded sentences using a customized script originally written by <span class="citation">Darwin (<a href="bibliography.html#ref-Darwin2005" role="doc-biblioref">2005</a>)</span> in Praat software <span class="citation">(<a href="bibliography.html#ref-Praat2001" role="doc-biblioref">Boersma, 2001</a>)</span>.
The speech signal was divided into 1, 4, 6, and 8 frequency bands between 70Hz and 9,000Hz.
The boundary frequencies were approximately logarithmically spaced following cochlear-frequency position functions <span class="citation">(<a href="bibliography.html#ref-Erb2014" role="doc-biblioref">Erb, 2014</a>; <a href="bibliography.html#ref-Greenwood1990" role="doc-biblioref">Greenwood, 1990</a>; <a href="bibliography.html#ref-Rosen1999" role="doc-biblioref">Rosen et al., 1999</a>)</span>.
The amplitude envelope of each band was extracted and applied to band-pass filtered white noise in the same frequency ranges;
the upper and lower bounds for band extraction are specified in Table <a href="chapter-methods.html#tab:frequencies">3.2</a>.
Modulated noise bands were then combined to produce a degraded speech.
Scaling was performed to equate the root-mean-square value of the original undistorted speech and the final degraded speech.
This resulted in four levels of degradation: 1-, 4-, 6-, and 8-channel noise-vocoded speech.</p>
<p>Spectrograms of clear speech and noise-vocoded speech for the sentence <em>Er löest die Aufgabe</em> are shown in Figure <a href="chapter-methods.html#fig:vocoding-spectrogram">3.2</a>. It shows that with a decrease in the number of noise-vocoding channels, the information in speech signal reduces and becomes noise-like.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:vocoding-spectrogram"></span>
<img src="figures/materials/aufgabe_clear.png" alt="Spectrograms of clear speech, and degraded speech arranged with a decreasing number of noise-vocoding channels (8, 6, 4 and 1 band) for the sentence `Er löest die Aufgabe.' " width="90%"><img src="figures/materials/aufgabe_8bands.png" alt="Spectrograms of clear speech, and degraded speech arranged with a decreasing number of noise-vocoding channels (8, 6, 4 and 1 band) for the sentence `Er löest die Aufgabe.' " width="90%"><img src="figures/materials/aufgabe_6bands.png" alt="Spectrograms of clear speech, and degraded speech arranged with a decreasing number of noise-vocoding channels (8, 6, 4 and 1 band) for the sentence `Er löest die Aufgabe.' " width="90%"><img src="figures/materials/aufgabe_4bands.png" alt="Spectrograms of clear speech, and degraded speech arranged with a decreasing number of noise-vocoding channels (8, 6, 4 and 1 band) for the sentence `Er löest die Aufgabe.' " width="90%"><img src="figures/materials/aufgabe_1band.png" alt="Spectrograms of clear speech, and degraded speech arranged with a decreasing number of noise-vocoding channels (8, 6, 4 and 1 band) for the sentence `Er löest die Aufgabe.' " width="90%"><p class="caption">
Figure 3.2: Spectrograms of clear speech, and degraded speech arranged with a decreasing number of noise-vocoding channels (8, 6, 4 and 1 band) for the sentence `Er löest die Aufgabe.’
</p>
</div>
<!--
```{=tex}
\begin{table}[H]
\begin{center}
\tiny
\caption{Boundary frequencies (in Hz) for 1, 4, 6 and 8 channels noise-vocoding conditions} 
\label{frequencies} 
\vskip 0.12in
\begin{tabular}{llllllllll} 
\hline
Number of channels     &    Boundary frequencies \\
\hline
1   &   70    &   9000   &     &     &       &       &        &       &   \\

4   &   70    &   423   &   1304  &   3504  &   9000    &       &        &       &   \\

6   &   70    &   268   &   633   &   1304  &   2539    &   4813    &    9000    &       &   \\

8   &   70    &   207   &   423   &   764   &   1304    &   2156    &    3504    &   5634    &   9000\\
\hline
\end{tabular} 
\end{center} 
\end{table}
```
-->
<div class="inline-table"><table style="width:100%;" class="table table-sm">
<caption>
<span id="tab:frequencies">Table 3.2: </span> Boundary frequencies (in Hz) for 1, 4, 6 and 8 channels noise-vocoding conditions</caption>
<colgroup>
<col width="9%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
<col width="10%">
</colgroup>
<thead><tr class="header">
<th align="left">Number of channels</th>
<th align="center">Boundary frequencies</th>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="center">70</td>
<td align="center">9000</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="center">70</td>
<td align="center">423</td>
<td align="center">1304</td>
<td align="center">3504</td>
<td align="center">9000</td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="odd">
<td align="left">6</td>
<td align="center">70</td>
<td align="center">268</td>
<td align="center">633</td>
<td align="center">1304</td>
<td align="center">2539</td>
<td align="center">4813</td>
<td align="center">9000</td>
<td align="center"></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="left">8</td>
<td align="center">70</td>
<td align="center">207</td>
<td align="center">423</td>
<td align="center">764</td>
<td align="center">1304</td>
<td align="center">2156</td>
<td align="center">3504</td>
<td align="center">5634</td>
<td align="center">9000</td>
</tr>
</tbody>
</table></div>
<p>The primary motivation to degrade speech signals by noise-vocoding is twofold:
On the practical side, noise-vocoding simulates the frequency selectivity with a cochlear implant or sensory-neural hearing loss.
This provides insight into speech perception and language comprehension in special populations (older adults with hearing loss, patients with cochlear implants).
On the experimental side, noise-vocoding preserves the temporal periodicity cues of the speech;
we can investigate the importance of specific suprasegmental cues in speech perception.
Noise-vocoding reduces the fine structure cues that carry the pitch-related suprasegmental information
and allows the study of temporal amplitude envelope cues, which carry the suprasegmental information involved in lexical processing;
noise-vocoding preserves these cues.
It also provides a control over speech intelligibility by varying the number of vocoder channels.</p>
</div>
<div id="compression-expansion" class="section level4" number="3.1.2.2">
<h4>
<span class="header-section-number">3.1.2.2</span> Speech compression and expansion<a class="anchor" aria-label="anchor" href="#compression-expansion"><i class="fas fa-link"></i></a>
</h4>
<p>Temporal compression and expansion are used as a method to simulate fast and slow speech, and
to study the effect of acoustic degradation (which is the change in speech rate) and the effect of increase or decrease in information flow.
As early as the mid-twentieth century, investigators reported that intelligibility does not drop significantly when speech is speeded up to 2 times the normal speech rate <span class="citation">(e.g., <a href="bibliography.html#ref-Garvey1953" role="doc-biblioref">Garvey, 1953</a>)</span>.
Speech rate was increased by chopping physical tapes.
Digital algorithms like PSOLA <span class="citation">(<a href="bibliography.html#ref-Charpentier1986" role="doc-biblioref">Charpentier &amp; Stella, 1986</a>; <a href="bibliography.html#ref-Moulines1990" role="doc-biblioref">Moulines &amp; Charpentier, 1990</a>)</span> developed in the 1980s and later <span class="citation">(e.g., <a href="bibliography.html#ref-Verhelst1993" role="doc-biblioref">Verhelst &amp; Roelands, 1993</a>)</span> now allow us to speed up and slow down the speech rate in a controlled fashion.
In Chapter 7, we used Praat software that utilises a uniform time-compression algorithm (PSOLA) to create slow and fast speech with the compression factor of 1.35 and 0.65, respectively.
A schematic representation of waveforms of different speech rates — normal, slow and fast — is shown in Figure <a href="chapter-methods.html#fig:speech-rate">3.3</a>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:speech-rate"></span>
<img src="figures/materials/aufgabe_fast.png" alt="Schematic representation of waveforms of fast, normal, and slow speech rates for the sentence `Er löest die Aufgabe' with the duration of each speech rates in second. Note the circled portion of the waveform, which examplifies that PSOLA eliminates and duplicates the parts of the original waveform to create fast and slow speech respectively." width="90%"><img src="figures/materials/aufgabe_normal.png" alt="Schematic representation of waveforms of fast, normal, and slow speech rates for the sentence `Er löest die Aufgabe' with the duration of each speech rates in second. Note the circled portion of the waveform, which examplifies that PSOLA eliminates and duplicates the parts of the original waveform to create fast and slow speech respectively." width="90%"><img src="figures/materials/aufgabe_slow.png" alt="Schematic representation of waveforms of fast, normal, and slow speech rates for the sentence `Er löest die Aufgabe' with the duration of each speech rates in second. Note the circled portion of the waveform, which examplifies that PSOLA eliminates and duplicates the parts of the original waveform to create fast and slow speech respectively." width="90%"><p class="caption">
Figure 3.3: Schematic representation of waveforms of fast, normal, and slow speech rates for the sentence `Er löest die Aufgabe’ with the duration of each speech rates in second. Note the circled portion of the waveform, which examplifies that PSOLA eliminates and duplicates the parts of the original waveform to create fast and slow speech respectively.
</p>
</div>
<p>PSOLA creates fast or slow speech in three steps: analysis, modification, and synthesis <span class="citation">(<a href="bibliography.html#ref-Charpentier1986" role="doc-biblioref">Charpentier &amp; Stella, 1986</a>; <a href="bibliography.html#ref-Taleb2020" role="doc-biblioref">Taleb, 2020</a>)</span>.
In the analysis step, it first sets pitch marks in an audio file and then creates segments of it
(i.e., it segments the signal into successive analysis windows centred around those pitch marks).
Then in the modification step, depending on the time-compression/expansion factor, it deletes (or duplicates) those segments and sets a new set of pitch marks.
Finally, in the synthesis step, it adds the new segments back to the audio file (i.e., it rearranges the analysis window) and creates fast or slow speech as required.
The distortion of phonemic properties of speech signals are minimal when accelerating and slowing down within the range of factor 2 or below <span class="citation">(<a href="bibliography.html#ref-Moulines1990" role="doc-biblioref">Moulines &amp; Charpentier, 1990</a>; cf. <a href="bibliography.html#ref-Longster2003" role="doc-biblioref">Longster, 2003</a>)</span>.</p>
<p>We create fast and slow versions of 120 high and 120 low predictability sentences.
These 480 recordings are then passed through 4 channels noise-vocoding to use as experimental materials.
As discussed <a href="chapter-introduction.html#research-goals">earlier</a>, the main aim of manipulating this bottom-up process is to investigate the effect of change in the rate of information flow (i.e., change in the speech rate) on the top-down processes of contextual facilitation in degraded speech comprehension.</p>
</div>
</div>
</div>
<div id="online-experiment" class="section level2" number="3.2">
<h2>
<span class="header-section-number">3.2</span> Data collection on the web<a class="anchor" aria-label="anchor" href="#online-experiment"><i class="fas fa-link"></i></a>
</h2>
<p>Traditionally, behavioural experiments with human participants are conducted in a laboratory setup.
In recent years, there has been a surge of experiments that are conducted on the web <span class="citation">(<a href="bibliography.html#ref-Reips2021" role="doc-biblioref">Reips, 2021</a>)</span>.
The first generation of online experiments to study human cognition began in the mid-1990s <span class="citation">(for reviews, <a href="bibliography.html#ref-Musch2000" role="doc-biblioref">Musch &amp; Reips, 2000</a>)</span> with the advent of the internet <span class="citation">(<a href="bibliography.html#ref-Bernerslee1992" role="doc-biblioref">Berners-Lee et al., 1992</a>)</span>.
<span class="citation">Welch &amp; Krantz (<a href="bibliography.html#ref-Welch1996" role="doc-biblioref">1996</a>)</span> was the first online experiment that was conducted in 1995 as a part of tutorials in auditory perception <span class="citation">(<a href="bibliography.html#ref-Musch2000" role="doc-biblioref">Musch &amp; Reips, 2000</a>)</span>.
In their survey of researchers, <span class="citation">Musch &amp; Reips (<a href="bibliography.html#ref-Musch2000" role="doc-biblioref">2000</a>)</span> discovered that until 2000, there were already at least two psycholinguistic experiments conducted online,
one of which studied the effect of context in shallow vs deep encoding of words.
Despite the difficulty in conducting online experiments and scepticism of journals towards publishing results of online experiments,
<span class="citation">Musch &amp; Reips (<a href="bibliography.html#ref-Musch2000" role="doc-biblioref">2000</a>)</span> expressed optimism:</p>
<blockquote>
<p>At the moment, the number of Web experiments is still small, but a rapid growth can be predicted on the basis of the present results.
We would not be surprised if within the next few years, a fair proportion of psychological experiments will be conducted on the Web. (p. 85)
<!-- > -->
<!-- > <footer>--- Musch & Reips, 2000, p. 85</footer> --></p>
</blockquote>
<p>By 2022, there has been significant growth in online experiments as technical and technological barriers are greatly reduced.
There are many software and online platforms which psychologists and psycholinguists can use with minimal knowledge of computer programming
to design, host and run their experiments and retrieve the data in a fairly structured format <span class="citation">(<a href="bibliography.html#ref-Anwylirvine2020" role="doc-biblioref">A. L. Anwyl-Irvine et al., 2020</a>; <a href="bibliography.html#ref-Peirce2019" role="doc-biblioref">Peirce et al., 2019</a>; <a href="bibliography.html#ref-Prolific" role="doc-biblioref">Prolific, 2014</a>; see also, <a href="bibliography.html#ref-Anwylirvine2021" role="doc-biblioref">A. Anwyl-Irvine et al., 2021</a>; <a href="bibliography.html#ref-Eyal2022" role="doc-biblioref">Peer et al., 2022</a>)</span>.
Online experiments have demonstrated advantages over laboratory experiments <span class="citation">(<a href="bibliography.html#ref-Gadiraju2017" role="doc-biblioref">Gadiraju et al., 2017</a>; <a href="bibliography.html#ref-Johnson2021" role="doc-biblioref">Johnson et al., 2021</a>)</span>.
For example, a large pool of participants is available online, which is usually not possible in laboratory experiments.
Similarly, the participants in online experiments are more diverse than in laboratory experiments.
Considering these advantages, psychologists and psycholinguists have conducted online experiments for almost three decades.
Scientists who only conducted laboratory experiments and occasional online experiments were forced to conduct their experiments almost exclusively on the web due to the restrictions imposed by covid-19 lockdown <span class="citation">(<a href="bibliography.html#ref-Gagne2021" role="doc-biblioref">Gagné &amp; Franzen, 2021</a>; <a href="bibliography.html#ref-Reips2021" role="doc-biblioref">Reips, 2021</a>)</span>.
Since <span class="citation">Welch &amp; Krantz (<a href="bibliography.html#ref-Welch1996" role="doc-biblioref">1996</a>)</span>’s auditory perception experiment, a number of experiments have been conducted online in the auditory domain <span class="citation">(<a href="bibliography.html#ref-Leensen2013" role="doc-biblioref">Leensen &amp; Dreschler, 2013</a>; <a href="bibliography.html#ref-Seow2022" role="doc-biblioref">Seow &amp; Hauser, 2022</a>; <a href="bibliography.html#ref-vanOs2021" role="doc-biblioref">van Os et al., 2021b</a>; <a href="bibliography.html#ref-Woods2017" role="doc-biblioref">Woods et al., 2017</a>)</span> replicating laboratory findings <span class="citation">(e.g., <a href="bibliography.html#ref-Cooke2021" role="doc-biblioref">Cooke &amp; Garcia Lecumberri, 2021</a>)</span>.
The experiments reported in this thesis were also conducted online.</p>
<p>Initially, our experiments were designed to be conducted both in the laboratory and on the web.
As the laboratory was shut down due to covid-19 pandemic-related lockdown (M. Schmitt, personal communication, March 16, 2020), we moved the laboratory experiments to the online platform.
We recruited participants online via Prolific Academic <span class="citation">(<a href="bibliography.html#ref-Prolific" role="doc-biblioref">Prolific, 2014</a>)</span>.
We used Prolific’s filters to recruit only native speakers of German residing in Germany
who reported not having any hearing loss, speech-language disorder, or cognitive impairment.
Participants were redirected to the experiments that were designed and hosted in Lingoturk <span class="citation">(<a href="bibliography.html#ref-Pusse2016" role="doc-biblioref">Pusse et al., 2016</a>)</span>.
Lingoturk is a local hosting platform that manages crowdsourcing experiments — it runs the experiments and stores the data.
We report the details of each experiment in Chapters 5, 6, and 7.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="chapter-background.html"><span class="header-section-number">2</span> Background</a></div>
<div class="next"><a href="chapter-stats.html"><span class="header-section-number">4</span> General statistical approach</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#chapter-methods"><span class="header-section-number">3</span> General methods</a></li>
<li>
<a class="nav-link" href="#experimental-materials"><span class="header-section-number">3.1</span> Experimental materials</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#stimulus-sentences"><span class="header-section-number">3.1.1</span> Stimulus sentences</a></li>
<li><a class="nav-link" href="#speech-processing"><span class="header-section-number">3.1.2</span> Speech processing</a></li>
</ul>
</li>
<li><a class="nav-link" href="#online-experiment"><span class="header-section-number">3.2</span> Data collection on the web</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/pratik-bhandari/blob/master/03-general-methods.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/pratik-bhandari/edit/master/03-general-methods.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong><p>Interaction of top-down and bottom-up processes in spoken language comprehension</p></strong>" was written by Pratik Bhandari. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
